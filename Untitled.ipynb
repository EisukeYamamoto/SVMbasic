{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目次\n",
    "1. SVMとは\n",
    "\n",
    "1. アヤメデータセットとは  \n",
    "\n",
    "1. アヤメデータ分類の流れ  \n",
    "\n",
    "\n",
    "### SVMとは\n",
    "サポートベクターマシン(Support Vector Machine)は、データを分類して境界線を引くアルゴリズムです。\n",
    "例として、架空の鳥の種類を分類する問題を考えてみます。\n",
    "\n",
    "下記の画像は、縦軸を「羽の大きさ」、横軸を「体の大きさ」とした2つの特徴量をもとに、AとBを分類したいとします。  \n",
    "\n",
    "では、どのように分類されるかを見ていきましょう。  \n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84215585-a9c81300-ab01-11ea-8147-f54844c0cc31.jpg\" width=60%>  \n",
    "\n",
    "下の図は、体の大きさだけで分類したものです。  \n",
    "\n",
    "体が小さければA、大きければBと判定されることになります。\n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84467516-67483700-acb7-11ea-87ae-79dee16ec529.png\" width=60%>  \n",
    "\n",
    "次の図は、体の大きさと、羽の大きさの両方を考慮して分類してみたものです。  \n",
    "\n",
    "体が小さいわりに羽が大きければA。体のわりに羽が小さければBとなります。\n",
    "    \n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84215595-b6e50200-ab01-11ea-8611-c4ca985d05dd.jpg\" width=60%>  \n",
    "\n",
    "この段階ではどちも正しく判別できているように見えます。　　\n",
    "\n",
    "例えば、下の図のように、B種のデータが追加で入ったとします。  \n",
    "\n",
    "新しいデータは、Bのほかのデータととても近い位置にプロットされています。  \n",
    "    \n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84557119-489f7a00-ad63-11ea-9759-c4eaedad4710.png\" width=60%>  \n",
    "    \n",
    "一番目の体の大きさだけで分類する場合、下記の左側の図のように、誤識別をします。　　\n",
    "\n",
    "一方で二つ目の体の大きさと羽の大きさで分類する場合、下記の右側の図のように、正しく分類します。\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84557095-10983700-ad63-11ea-9650-16e946fbfd55.png\" width=50%><img src=\"https://user-images.githubusercontent.com/51330824/84557098-2279da00-ad63-11ea-9265-998c5d0d4744.png\" width=50%>  \n",
    "\n",
    "SVMでは、正しい分類基準を見つけるために、マージン最大化という考えを使います。  \n",
    "\n",
    "マージンとは、判別する境界とデータとの距離を指します。  \n",
    "\n",
    "これが大きければ、ほんの少しデータが変わっただけで誤識別してしまうというミスをなくすことができます。  \n",
    "\n",
    "なお、境界線と最も近くにあるデータを「サポートベクトル」と呼びます。  \n",
    "    \n",
    "<div align=\"center\">\n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84557346-4f2ef100-ad65-11ea-97c8-a280cac4220f.png\" width=60%>    \n",
    "    \n",
    "境界近くにあるデータは、「AかBか微妙」な位置にあるデータであり、境界とデータとの距離、すなわちマージンを大きくするようにして誤識別を防ぎます。  \n",
    "\n",
    "なので、誤識別を防ぐには「境界の近くにあるデータ」だけあれば十分に識別することができます。  \n",
    "    \n",
    "SVMを使うメリットとして、以下のようなことがあります。  \n",
    "    \n",
    "・簡単に実装できること  \n",
    "    \n",
    "・分類精度が高い  \n",
    " \n",
    "・分類する境界線が非線形にも対応　などが挙げられます。  \n",
    "\n",
    "<!-- 先ほどの例では、AとBの2クラスを分類していました。他にも、3クラス分類や4クラス以上の多クラス分類も可能です。   -->\n",
    "　　\n",
    "\n",
    "今回の実習では、3クラスでの分類を行います。\n",
    "\n",
    "### アヤメデータセットとは\n",
    "機械学習でよく使われるアヤメの品種のデータです。アヤメの品種である**Setosa Versicolor Virginica**の3品種に関する150件のデータが入っています。  \n",
    "<div align=\"center\">  \n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84467525-6f07db80-acb7-11ea-8a46-9401185a02bb.png\" width=100%>  \n",
    "\n",
    "データセットの中身は**Sepal Length（がく片の長さ）、 Sepal Width（がく片の幅）、 Petal Length（花びらの長さ）、 Petal Width（花びらの幅）**の4つの特徴量を持っています。\n",
    "\n",
    "### アヤメデータ分類の流れ\n",
    "\n",
    "実習の目的は、アヤメのがく片や花びらの幅や長さの数値を用いてSVMでアヤメの品種を分類します。  \n",
    "\n",
    "#### 1.データの読み込み  \n",
    "まず、データを読み込みます。データの中身は以下のようになっています。  \n",
    "\n",
    "||Sepal(がく)Length|SepalWidth|Petal(花びら)Length|PetalWidth|Name  \n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|  \n",
    "|0|5.1|3.5|1.4|0.2|Iris-setosa|  \n",
    "|1|4.9|3.0|1.4|0.2|Iris-setosa|  \n",
    "|2|4.7|3.2|1.3|0.2|Iris-setosa|  \n",
    "・・・（省略）  \n",
    "|70|...|...|...|...|Iris-versicolor|  \n",
    "...(省略)\n",
    "|149|...|...|...|...|Iris-virginica|\n",
    "\n",
    "#### 2.説明変数と目的変数に分ける  \n",
    "csvファイルを読み込めたら、目的変数に当たる品種名と、説明変数にあたるデータ(がく片と花びらの長さ)に分けていきます。  \n",
    "\n",
    "|説明変数|目的変数|\n",
    "|:---:|:---:|\n",
    "|がく片の長さ||  \n",
    "|がく片の幅|・setosa|  \n",
    "|花びらの長さ|・versicolor|  \n",
    "|花びらの幅|・virginica|  \n",
    "    \n",
    "データの分け方は実習で詳しく説明します。\n",
    "\n",
    "#### 3.学習用データとテスト用データに分ける  \n",
    "    \n",
    "||Sepal(がく)Length|SepalWidth|Petal(花びら)Length|PetalWidth|Name  \n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|  \n",
    "|4|5.1|3.5|1.4|0.2|Iris-setosa|  \n",
    "|6|4.9|3.0|1.4|0.2|Iris-setosa|  \n",
    "・・・（省略）  \n",
    "|90|...|...|...|...|Iris-versicolor|  \n",
    "...(省略)\n",
    "|149|...|...|...|...|Iris-virginica|\n",
    "    \n",
    "教師あり機械学習(SVM)によるモデルを作成するには、学習用データとテスト用データの二つに分割し、予測モデルの作成、評価を行うのが一般的です。  \n",
    "\n",
    "今回、アヤメデータは150データあるので、105の学習用データと45のテスト用データ（7:3）に分けます。分け方はランダムで行います。　　\n",
    "\n",
    "#### 4.学習させて評価する   \n",
    "\n",
    "<div align=\"center\">  \n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84804460-c8686580-b03d-11ea-8241-5400b9e18c80.png\" width=100%>  \n",
    "    \n",
    "上図のように先ほど150データの内105データを学習データにしました。この105データの説明変数(4つの特徴量)と目的変数(アヤメの名前)の関係性を学習し、説明変数が与えられたときに目的変数を返すモデルを作成します。(説明変数と目的変数の関連性を学び、説明変数で目的変数を予測する)  \n",
    "    \n",
    "続いて、下図のようにテスト用データにした45のデータの説明変数のみと作成したモデルを用いて、予測結果を算出します。  \n",
    "     \n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84805853-d6b78100-b03f-11ea-9207-cc212693f548.png\" width=60%>  <img src=\"https://user-images.githubusercontent.com/51330824/84806144-36159100-b040-11ea-9046-8df2b060808c.png\" width=20%>  \n",
    "\n",
    "求めた予測結果と実際のアヤメの種類と比較することで、どれだけ正しく予測できるか(確率)確認することで、モデルの予測性能を測ります。  \n",
    "    \n",
    "<img src=\"https://user-images.githubusercontent.com/51330824/84806868-5003a380-b041-11ea-822a-ac85b0d60ca9.png\" width=60%>  <img src=\"https://user-images.githubusercontent.com/51330824/84806144-36159100-b040-11ea-9046-8df2b060808c.png\" width=20%>  \n",
    "\n",
    "それでは、実際にPythonを使ってSVMをやってみましょう。  \n",
    "\n",
    "    \n",
    "<参考文献>  \n",
    "・サポートベクターマシンの考え方  \n",
    "https://logics-of-blue.com/svm-concept/  \n",
    "・初心者に向けてアヤメ分類を一から解説してみた  \n",
    "https://qiita.com/Hirochon/items/12379d7ca6141f1fb6fa  \n",
    "・アヤメデータを使った機械学習の流れを簡単にまとめてみた  \n",
    "https://yolo.love/scikit-learn/iris/  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
